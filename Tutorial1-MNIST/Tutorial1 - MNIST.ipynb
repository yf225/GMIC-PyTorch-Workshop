{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MNIST dataset in Visdom\n",
    "# Train MNIST\n",
    "# Plot loss curve with Visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, open Terminal and type:\n",
    "\n",
    "# python -m visdom.server\n",
    "\n",
    "# Then, open browser and go to http://localhost:8097/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: talk more about what these compose options do\n",
    "transf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, ), (1.0, ))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MNIST(root='./data', train=True, transform=transf, download=False) # load training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.train_data.shape # see dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    3,   18,   18,   18,  126,  136,  175,   26,\n",
       "          166,  255,  247,  127,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,   30,   36,\n",
       "           94,  154,  170,  253,  253,  253,  253,  253,  225,  172,\n",
       "          253,  242,  195,   64,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,   49,  238,  253,\n",
       "          253,  253,  253,  253,  253,  253,  253,  251,   93,   82,\n",
       "           82,   56,   39,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,   18,  219,  253,\n",
       "          253,  253,  253,  253,  198,  182,  247,  241,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,   80,  156,\n",
       "          107,  253,  253,  205,   11,    0,   43,  154,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,   14,\n",
       "            1,  154,  253,   90,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,  139,  253,  190,    2,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,   11,  190,  253,   70,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,   35,  241,  225,  160,  108,    1,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,   81,  240,  253,  253,  119,   25,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,   45,  186,  253,  253,  150,   27,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,   16,   93,  252,  253,  187,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,  249,  253,  249,\n",
       "           64,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,   46,  130,  183,  253,  253,  207,\n",
       "            2,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,   39,  148,  229,  253,  253,  253,  250,  182,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           24,  114,  221,  253,  253,  253,  253,  201,   78,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,   23,   66,\n",
       "          213,  253,  253,  253,  253,  198,   81,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,   18,  171,  219,  253,\n",
       "          253,  253,  253,  195,   80,    9,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,   55,  172,  226,  253,  253,  253,\n",
       "          253,  244,  133,   11,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,  136,  253,  253,  253,  212,  135,\n",
       "          132,   16,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To visualize the samples in dataset, let's use Visdom\n",
    "from visdom import Visdom\n",
    "vis = Visdom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'window_3629a842760a12'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis.image(train_set.train_data[0]) # See image in Visdom page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = MNIST(root='./data', train=False, transform=transf, download=False) # load training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid # Combine images into a nice-looking grid layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# first 10 samples combined together\n",
    "# MNIST dataset doesn't have channel dimension, so we use unsqueeze to manually add it\n",
    "print(train_set.train_data.shape)\n",
    "print(train_set.train_data.unsqueeze(1).shape)\n",
    "combined_image = make_grid(train_set.train_data[:10].unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'window_3629a8428cca40'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis.image(combined_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better way to visualize how good our model does\n",
    "# For each target value (0-9), see how often our model gets it right\n",
    "def confusion(model, n, dataset):\n",
    "    conf = torch.zeros(n, n)\n",
    "    model.eval() # Put model in evaluation mode\n",
    "    for data, target in dataset:\n",
    "        data = data.unsqueeze(1)\n",
    "        output = model(data)\n",
    "        _, pred = torch.max(output.data, 1)\n",
    "        conf[target][pred[0]] += 1\n",
    "        \n",
    "    # Normalize\n",
    "    for i in range(n):\n",
    "        conf[i] = conf[i] / conf[i].sum()\n",
    "        \n",
    "    vis.image(conf)\n",
    "    \n",
    "# A perfect model should show a diagonal white line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our own CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(20 * 4 * 4, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # we can also use functional interface for Conv2d and pass in the weights and biases, useful in weight sharing scenario\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 20 * 4 * 4) # -1 means we only care about the size of the last dimension, and just merge the rest of the dimensions into one\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we train the model, let's define the method for plotting the loss curve\n",
    "import numpy as np\n",
    "def plot_loss_curve(epoch, nepochs, loss, accuracy):\n",
    "    vis.line(\n",
    "        X = np.column_stack(([epoch], [epoch])),\n",
    "        Y = np.column_stack(([loss], [accuracy])),\n",
    "        win = 'loss_curve',\n",
    "        opts = dict(\n",
    "            title='MNIST loss curve', # Set the title of the plot\n",
    "            legend=['Loss', 'Accuracy'], # Set name for each curve\n",
    "            xtickmin=0,\n",
    "            xtickmax=nepochs,\n",
    "            xtickstep=0.01,\n",
    "            ytickmin=0,\n",
    "            ytickmax=1.5,\n",
    "            ytickstep=0.01\n",
    "        ),\n",
    "        update = None if epoch == 0 else 'append'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_set, test_set, nepochs):\n",
    "    batch_size = 500\n",
    "    # dataloader can help you get batched data and shuffle the data\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_set)\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.03, momentum=0.5)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(nepochs):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad() # This will zero out all the gradients for the model's parameters\n",
    "            output = model(data) # This is a softmax output over the possible labels\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch_idx % 50 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), float(loss)))\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).data.item()\n",
    "            \n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            \n",
    "            correct += (pred == target.data).sum()\n",
    "            \n",
    "        test_loss /= len(test_set)\n",
    "        accuracy = float(correct)/len(test_set)\n",
    "        print(\"Loss: {:.6f}\".format(test_loss), \"Accuracy: \", accuracy)\n",
    "        plot_loss_curve(epoch, nepochs, test_loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.301107\n",
      "Train Epoch: 0 [25000/60000 (42%)]\tLoss: 2.261651\n",
      "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.925754\n",
      "Loss:  1.1276718949869275 Accuracy:  0.7508\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 1.165561\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.419964\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.420000\n",
      "Loss:  0.34246425257586816 Accuracy:  0.8935\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.394286\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.316114\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.224696\n",
      "Loss:  0.21831342190593422 Accuracy:  0.9312\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.278661\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.230181\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.195008\n",
      "Loss:  0.163646366741533 Accuracy:  0.95\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.154957\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.170631\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.167735\n",
      "Loss:  0.12565901902516813 Accuracy:  0.9603\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.104393\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.133537\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.115568\n",
      "Loss:  0.10960941952834391 Accuracy:  0.9658\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.113362\n",
      "Train Epoch: 6 [25000/60000 (42%)]\tLoss: 0.084855\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.098283\n",
      "Loss:  0.09313334423465265 Accuracy:  0.9701\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.086673\n",
      "Train Epoch: 7 [25000/60000 (42%)]\tLoss: 0.131235\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.124336\n",
      "Loss:  0.0824841530291277 Accuracy:  0.9731\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.097777\n",
      "Train Epoch: 8 [25000/60000 (42%)]\tLoss: 0.097127\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.077958\n",
      "Loss:  0.08103953496123555 Accuracy:  0.9748\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.111532\n",
      "Train Epoch: 9 [25000/60000 (42%)]\tLoss: 0.078709\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.059339\n",
      "Loss:  0.0717589468666493 Accuracy:  0.9765\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_set, test_set, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion(model, 10, test_set) # See confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model state as checkpoint, to be used later\n",
    "torch.save(model.state_dict(), 'mnist.pth')\n",
    "\n",
    "# Load model into another variable\n",
    "new_model = CNN()\n",
    "new_model.load_state_dict(torch.load('mnist.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: for transfer learning, make sure the two linear layers are replaced"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
