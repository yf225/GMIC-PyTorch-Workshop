{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Transfer learning from MNIST to USPS!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import sys\n",
    "from dataset.usps import USPS\n",
    "import numpy as np\n",
    "# from visdom import Visdom\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up argument parser for command line arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser(description='PyTorch USPS Transfer Learning Example')\n",
    "# parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "#                     help='number of epochs to train (default: 10)')\n",
    "# parser.add_argument('--fine-tuning-on-mnist', type=str,\n",
    "#                     help='type of fine tuning on pretrained MNIST model, can be none/last-layer/all-layers')\n",
    "# parser.add_argument('--mnist-pretrained-model', type=str, \n",
    "#                     help='path to MNIST pretrained model')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# Parameters\n",
    "epochs = 10 # number of epochs to train (default: 10)\n",
    "fine_tuning_on_mnist = 'last-layer' # 'last-layer' / 'all-layers'\n",
    "mnist_pretrained_model = 'mnist_models/mnist.pth' # path to MNIST pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Visdom (for visualizing loss curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curve(nepochs, test_losses, accuracies):\n",
    "    plt.title('USPS loss curve, fine tune: ' + fine_tuning_on_mnist)\n",
    "    plt.xticks(np.arange(0, nepochs, 1))\n",
    "    plt.plot(range(nepochs), test_losses, 'r--', label='Loss')\n",
    "    plt.plot(range(nepochs), accuracies, 'b', label='Accuracy')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up model and optimizer. Decide which fine-tuning method to use\n",
    "(no tuning / tuning only last layer / tuning all layers) for transfer\n",
    "learning from MNIST model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTNet()\n",
    "\n",
    "layers_to_tune = model\n",
    "\n",
    "if fine_tuning_on_mnist in ['last-layer', 'all-layers']:\n",
    "    pretrained_model_path = mnist_pretrained_model\n",
    "    model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "    if fine_tuning_on_mnist == 'last-layer':\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = False\n",
    "        # Replace the last layer with a new uninitiated one, and only tune the parameters for this layer\n",
    "        model.fc2 = nn.Linear(50, 10)\n",
    "        layers_to_tune = model.fc2\n",
    "\n",
    "optimizer = optim.SGD(layers_to_tune.parameters(), lr=0.001, momentum=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_process = transforms.Compose([transforms.ToTensor(),\n",
    "                                  transforms.Normalize(\n",
    "                                  mean=(0.5,),\n",
    "                                  std=(0.5,))])\n",
    "\n",
    "usps_dataset_train = USPS(root=\"data\",\n",
    "                    train=True,\n",
    "                    transform=pre_process,\n",
    "                    download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                    dataset=usps_dataset_train,\n",
    "                    batch_size=64,\n",
    "                    shuffle=True)\n",
    "\n",
    "usps_dataset_test = USPS(root=\"data\",\n",
    "                    train=False,\n",
    "                    transform=pre_process,\n",
    "                    download=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                    dataset=usps_dataset_test,\n",
    "                    batch_size=1000,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    num_batches = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        target = target.reshape(-1)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), float(loss)))\n",
    "        num_batches += 1\n",
    "    torch.save(model.state_dict(), 'checkpoints/usps_%s.pth' % (epoch, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method for testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        target = target.reshape(-1)\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "            test_loss += float(F.nll_loss(output, target, size_average=False)) # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += int(pred.eq(target.data.view_as(pred)).cpu().long().sum())\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = correct * 1.0 / len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * accuracy))\n",
    "    \n",
    "    return test_loss, accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test the model for a few epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/7438 (0%)]\tLoss: 5.880067\n",
      "Train Epoch: 1 [640/7438 (9%)]\tLoss: 5.225685\n",
      "Train Epoch: 1 [1280/7438 (17%)]\tLoss: 3.710082\n",
      "Train Epoch: 1 [1920/7438 (26%)]\tLoss: 3.927562\n",
      "Train Epoch: 1 [2560/7438 (34%)]\tLoss: 3.075169\n",
      "Train Epoch: 1 [3200/7438 (43%)]\tLoss: 2.937549\n",
      "Train Epoch: 1 [3840/7438 (51%)]\tLoss: 2.648147\n",
      "Train Epoch: 1 [4480/7438 (60%)]\tLoss: 3.093939\n",
      "Train Epoch: 1 [5120/7438 (68%)]\tLoss: 2.586032\n",
      "Train Epoch: 1 [5760/7438 (77%)]\tLoss: 2.135638\n",
      "Train Epoch: 1 [6400/7438 (85%)]\tLoss: 1.915341\n",
      "Train Epoch: 1 [7040/7438 (94%)]\tLoss: 2.025569\n",
      "\n",
      "Test set: Average loss: 0.8840, Accuracy: 1481/1860 (80%)\n",
      "\n",
      "Train Epoch: 2 [0/7438 (0%)]\tLoss: 2.678517\n",
      "Train Epoch: 2 [640/7438 (9%)]\tLoss: 3.160967\n",
      "Train Epoch: 2 [1280/7438 (17%)]\tLoss: 2.647947\n",
      "Train Epoch: 2 [1920/7438 (26%)]\tLoss: 2.281165\n",
      "Train Epoch: 2 [2560/7438 (34%)]\tLoss: 1.952005\n",
      "Train Epoch: 2 [3200/7438 (43%)]\tLoss: 2.310044\n",
      "Train Epoch: 2 [3840/7438 (51%)]\tLoss: 2.235347\n",
      "Train Epoch: 2 [4480/7438 (60%)]\tLoss: 1.838920\n",
      "Train Epoch: 2 [5120/7438 (68%)]\tLoss: 1.593672\n",
      "Train Epoch: 2 [5760/7438 (77%)]\tLoss: 2.071224\n",
      "Train Epoch: 2 [6400/7438 (85%)]\tLoss: 1.508248\n",
      "Train Epoch: 2 [7040/7438 (94%)]\tLoss: 1.406257\n",
      "\n",
      "Test set: Average loss: 0.6656, Accuracy: 1593/1860 (86%)\n",
      "\n",
      "Train Epoch: 3 [0/7438 (0%)]\tLoss: 2.941863\n",
      "Train Epoch: 3 [640/7438 (9%)]\tLoss: 2.730476\n",
      "Train Epoch: 3 [1280/7438 (17%)]\tLoss: 2.780963\n",
      "Train Epoch: 3 [1920/7438 (26%)]\tLoss: 2.390261\n",
      "Train Epoch: 3 [2560/7438 (34%)]\tLoss: 2.216156\n",
      "Train Epoch: 3 [3200/7438 (43%)]\tLoss: 2.015877\n",
      "Train Epoch: 3 [3840/7438 (51%)]\tLoss: 2.519791\n",
      "Train Epoch: 3 [4480/7438 (60%)]\tLoss: 1.865698\n",
      "Train Epoch: 3 [5120/7438 (68%)]\tLoss: 2.112840\n",
      "Train Epoch: 3 [5760/7438 (77%)]\tLoss: 2.037410\n",
      "Train Epoch: 3 [6400/7438 (85%)]\tLoss: 1.621890\n",
      "Train Epoch: 3 [7040/7438 (94%)]\tLoss: 2.114610\n",
      "\n",
      "Test set: Average loss: 0.8939, Accuracy: 1399/1860 (75%)\n",
      "\n",
      "Train Epoch: 4 [0/7438 (0%)]\tLoss: 3.563182\n",
      "Train Epoch: 4 [640/7438 (9%)]\tLoss: 3.255805\n",
      "Train Epoch: 4 [1280/7438 (17%)]\tLoss: 3.459694\n",
      "Train Epoch: 4 [1920/7438 (26%)]\tLoss: 4.173921\n",
      "Train Epoch: 4 [2560/7438 (34%)]\tLoss: 3.496629\n",
      "Train Epoch: 4 [3200/7438 (43%)]\tLoss: 2.898358\n",
      "Train Epoch: 4 [3840/7438 (51%)]\tLoss: 3.693812\n",
      "Train Epoch: 4 [4480/7438 (60%)]\tLoss: 3.586621\n",
      "Train Epoch: 4 [5120/7438 (68%)]\tLoss: 4.088897\n",
      "Train Epoch: 4 [5760/7438 (77%)]\tLoss: 4.229986\n",
      "Train Epoch: 4 [6400/7438 (85%)]\tLoss: 4.134034\n",
      "Train Epoch: 4 [7040/7438 (94%)]\tLoss: 3.919901\n",
      "\n",
      "Test set: Average loss: 5.3809, Accuracy: 415/1860 (22%)\n",
      "\n",
      "Train Epoch: 5 [0/7438 (0%)]\tLoss: 14.963514\n",
      "Train Epoch: 5 [640/7438 (9%)]\tLoss: 22.238111\n",
      "Train Epoch: 5 [1280/7438 (17%)]\tLoss: 22.323072\n",
      "Train Epoch: 5 [1920/7438 (26%)]\tLoss: 20.524052\n",
      "Train Epoch: 5 [2560/7438 (34%)]\tLoss: 22.846384\n",
      "Train Epoch: 5 [3200/7438 (43%)]\tLoss: 28.941652\n",
      "Train Epoch: 5 [3840/7438 (51%)]\tLoss: 22.806057\n",
      "Train Epoch: 5 [4480/7438 (60%)]\tLoss: 21.615191\n",
      "Train Epoch: 5 [5120/7438 (68%)]\tLoss: 16.855785\n",
      "Train Epoch: 5 [5760/7438 (77%)]\tLoss: 22.623940\n",
      "Train Epoch: 5 [6400/7438 (85%)]\tLoss: 20.797617\n",
      "Train Epoch: 5 [7040/7438 (94%)]\tLoss: 16.000717\n",
      "\n",
      "Test set: Average loss: 18.3334, Accuracy: 472/1860 (25%)\n",
      "\n",
      "Train Epoch: 6 [0/7438 (0%)]\tLoss: 56.355450\n",
      "Train Epoch: 6 [640/7438 (9%)]\tLoss: 70.895012\n",
      "Train Epoch: 6 [1280/7438 (17%)]\tLoss: 43.025890\n",
      "Train Epoch: 6 [1920/7438 (26%)]\tLoss: 56.523018\n",
      "Train Epoch: 6 [2560/7438 (34%)]\tLoss: 72.488884\n",
      "Train Epoch: 6 [3200/7438 (43%)]\tLoss: 58.707066\n",
      "Train Epoch: 6 [3840/7438 (51%)]\tLoss: 62.313515\n",
      "Train Epoch: 6 [4480/7438 (60%)]\tLoss: 67.053116\n",
      "Train Epoch: 6 [5120/7438 (68%)]\tLoss: 102.530502\n",
      "Train Epoch: 6 [5760/7438 (77%)]\tLoss: 89.385345\n",
      "Train Epoch: 6 [6400/7438 (85%)]\tLoss: 67.590057\n",
      "Train Epoch: 6 [7040/7438 (94%)]\tLoss: 72.667908\n",
      "\n",
      "Test set: Average loss: 32.0984, Accuracy: 710/1860 (38%)\n",
      "\n",
      "Train Epoch: 7 [0/7438 (0%)]\tLoss: 115.866348\n",
      "Train Epoch: 7 [640/7438 (9%)]\tLoss: 561.651672\n",
      "Train Epoch: 7 [1280/7438 (17%)]\tLoss: 434.362274\n",
      "Train Epoch: 7 [1920/7438 (26%)]\tLoss: 337.588165\n",
      "Train Epoch: 7 [2560/7438 (34%)]\tLoss: 224.258636\n",
      "Train Epoch: 7 [3200/7438 (43%)]\tLoss: 155.850922\n",
      "Train Epoch: 7 [3840/7438 (51%)]\tLoss: 390.291321\n",
      "Train Epoch: 7 [4480/7438 (60%)]\tLoss: 380.253601\n",
      "Train Epoch: 7 [5120/7438 (68%)]\tLoss: 469.576294\n",
      "Train Epoch: 7 [5760/7438 (77%)]\tLoss: 337.421967\n",
      "Train Epoch: 7 [6400/7438 (85%)]\tLoss: 293.652191\n",
      "Train Epoch: 7 [7040/7438 (94%)]\tLoss: 292.129639\n",
      "\n",
      "Test set: Average loss: 144.7902, Accuracy: 871/1860 (47%)\n",
      "\n",
      "Train Epoch: 8 [0/7438 (0%)]\tLoss: 631.054932\n",
      "Train Epoch: 8 [640/7438 (9%)]\tLoss: 2159.071777\n",
      "Train Epoch: 8 [1280/7438 (17%)]\tLoss: 1363.762817\n",
      "Train Epoch: 8 [1920/7438 (26%)]\tLoss: 1253.524536\n",
      "Train Epoch: 8 [2560/7438 (34%)]\tLoss: 1283.993164\n",
      "Train Epoch: 8 [3200/7438 (43%)]\tLoss: 906.579468\n",
      "Train Epoch: 8 [3840/7438 (51%)]\tLoss: 1346.184082\n",
      "Train Epoch: 8 [4480/7438 (60%)]\tLoss: 1799.744263\n",
      "Train Epoch: 8 [5120/7438 (68%)]\tLoss: 873.140686\n",
      "Train Epoch: 8 [5760/7438 (77%)]\tLoss: 1210.238525\n",
      "Train Epoch: 8 [6400/7438 (85%)]\tLoss: 1389.038330\n",
      "Train Epoch: 8 [7040/7438 (94%)]\tLoss: 973.773804\n",
      "\n",
      "Test set: Average loss: 504.8764, Accuracy: 839/1860 (45%)\n",
      "\n",
      "Train Epoch: 9 [0/7438 (0%)]\tLoss: 2345.030273\n",
      "Train Epoch: 9 [640/7438 (9%)]\tLoss: 4504.690430\n",
      "Train Epoch: 9 [1280/7438 (17%)]\tLoss: 4988.716797\n",
      "Train Epoch: 9 [1920/7438 (26%)]\tLoss: 5540.234863\n",
      "Train Epoch: 9 [2560/7438 (34%)]\tLoss: 7136.885254\n",
      "Train Epoch: 9 [3200/7438 (43%)]\tLoss: 6196.655273\n",
      "Train Epoch: 9 [3840/7438 (51%)]\tLoss: 4742.362305\n",
      "Train Epoch: 9 [4480/7438 (60%)]\tLoss: 4722.039062\n",
      "Train Epoch: 9 [5120/7438 (68%)]\tLoss: 3793.571533\n",
      "Train Epoch: 9 [5760/7438 (77%)]\tLoss: 2800.980957\n",
      "Train Epoch: 9 [6400/7438 (85%)]\tLoss: 4871.590820\n",
      "Train Epoch: 9 [7040/7438 (94%)]\tLoss: 3339.974609\n",
      "\n",
      "Test set: Average loss: 7677.9390, Accuracy: 275/1860 (15%)\n",
      "\n",
      "Train Epoch: 10 [0/7438 (0%)]\tLoss: 20820.537109\n",
      "Train Epoch: 10 [640/7438 (9%)]\tLoss: 35896.828125\n",
      "Train Epoch: 10 [1280/7438 (17%)]\tLoss: 17233.505859\n",
      "Train Epoch: 10 [1920/7438 (26%)]\tLoss: 19946.464844\n",
      "Train Epoch: 10 [2560/7438 (34%)]\tLoss: 19294.714844\n",
      "Train Epoch: 10 [3200/7438 (43%)]\tLoss: 15795.380859\n",
      "Train Epoch: 10 [3840/7438 (51%)]\tLoss: 19132.083984\n",
      "Train Epoch: 10 [4480/7438 (60%)]\tLoss: 22258.589844\n",
      "Train Epoch: 10 [5120/7438 (68%)]\tLoss: 14251.005859\n",
      "Train Epoch: 10 [5760/7438 (77%)]\tLoss: 19508.794922\n",
      "Train Epoch: 10 [6400/7438 (85%)]\tLoss: 12628.641602\n",
      "Train Epoch: 10 [7040/7438 (94%)]\tLoss: 21148.068359\n",
      "\n",
      "Test set: Average loss: 24128.8032, Accuracy: 767/1860 (41%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_losses = []\n",
    "accuracies = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    test_loss, accuracy = test(epoch)\n",
    "    test_losses.append(test_loss)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "plot_loss_curve(epoch, test_losses, accuracies)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install -r requirements.txt\n",
    "\n",
    "python main.py --fine-tuning-on-mnist=none --mnist-pretrained-model=mnist_models/mnist_10.pth\n",
    "\n",
    "python main.py --fine-tuning-on-mnist=last-layers --mnist-pretrained-model=mnist_models/mnist_10.pth\n",
    "\n",
    "python main.py --fine-tuning-on-mnist=all-layers --mnist-pretrained-model=mnist_models/mnist_10.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
