{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Transfer learning from MNIST to USPS!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import sys\n",
    "from dataset.usps import USPS\n",
    "import numpy as np\n",
    "from visdom import Visdom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up argument parser for command line arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch USPS Transfer Learning Example')\n",
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--fine-tuning-on-mnist', type=str,\n",
    "                    help='type of fine tuning on pretrained MNIST model, can be none/last-layer/all-layers')\n",
    "parser.add_argument('--mnist-pretrained-model', type=str, \n",
    "                    help='path to MNIST pretrained model')\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Visdom (for visualizing loss curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vis = Visdom()\n",
    "\n",
    "def plot_loss_curve(epoch, loss, accuracy):\n",
    "    vis.line(\n",
    "        X = np.column_stack(([epoch], [epoch])),\n",
    "        Y = np.column_stack(([loss], [accuracy])),\n",
    "        win = 'loss_curve_' + args.fine_tuning_on_mnist,\n",
    "        opts = dict(\n",
    "            title='USPS loss curve, fine tune: ' + args.fine_tuning_on_mnist,\n",
    "            legend=['Loss', 'Accuracy'],\n",
    "            xtickmin=0,\n",
    "            xtickmax=args.epochs,\n",
    "            xtickstep=0.01,\n",
    "            ytickmin=0,\n",
    "            ytickmax=2,\n",
    "            ytickstep=0.01\n",
    "        ),\n",
    "        update = None if epoch == 1 else 'append'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up model and optimizer. Decide which fine-tuning method to use\n",
    "(no tuning / tuning only last layer / tuning all layers) for transfer\n",
    "learning from MNIST model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = MNISTNet()\n",
    "\n",
    "layers_to_tune = model\n",
    "\n",
    "if args.fine_tuning_on_mnist in ['last-layer', 'all-layers']:\n",
    "    pretrained_model_path = args.mnist_pretrained_model\n",
    "    model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "    if args.fine_tuning_on_mnist == 'last-layer':\n",
    "        # Replace the last layer with a new uninitiated one, and only tune the parameters for this layer\n",
    "        model.fc2 = nn.Linear(50, 10)\n",
    "        layers_to_tune = model.fc2\n",
    "\n",
    "optimizer = optim.SGD(layers_to_tune.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_process = transforms.Compose([transforms.ToTensor(),\n",
    "                                  transforms.Normalize(\n",
    "                                  mean=(0.5, 0.5, 0.5),\n",
    "                                  std=(0.5, 0.5, 0.5))])\n",
    "\n",
    "usps_dataset_train = USPS(root=\"data\",\n",
    "                    train=True,\n",
    "                    transform=pre_process,\n",
    "                    download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                    dataset=usps_dataset_train,\n",
    "                    batch_size=64,\n",
    "                    shuffle=True)\n",
    "\n",
    "usps_dataset_test = USPS(root=\"data\",\n",
    "                    train=False,\n",
    "                    transform=pre_process,\n",
    "                    download=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                    dataset=usps_dataset_test,\n",
    "                    batch_size=1000,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    num_batches = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        target = target.reshape(-1)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), float(loss)))\n",
    "        num_batches += 1\n",
    "    torch.save(model.state_dict(), 'checkpoints/usps_%s.pth' % (epoch, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method for testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        target = target.reshape(-1)\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "            test_loss += float(F.nll_loss(output, target, size_average=False)) # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += int(pred.eq(target.data.view_as(pred)).cpu().long().sum())\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = correct * 1.0 / len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * accuracy))\n",
    "\n",
    "    plot_loss_curve(epoch, test_loss, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test the model for a few epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this example, do the following (also open http://localhost:8097/ to visualize the loss curve):"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install -r requirements.txt\n",
    "\n",
    "python main.py --fine-tuning-on-mnist=none --mnist-pretrained-model=mnist_models/mnist_10.pth\n",
    "\n",
    "python main.py --fine-tuning-on-mnist=last-layers --mnist-pretrained-model=mnist_models/mnist_10.pth\n",
    "\n",
    "python main.py --fine-tuning-on-mnist=all-layers --mnist-pretrained-model=mnist_models/mnist_10.pth"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
